{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем синтетические данные для регрессии"
      ],
      "metadata": {
        "id": "cKfiGN44VtcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "Mp_EjyAg0rSl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset for linear regression with random parameters generation\n",
        "\n",
        "# features = np.random.randint(5, 51)\n",
        "features = 5\n",
        "informative = int(features * np.random.random_sample())\n",
        "noise = np.random.random_sample()\n",
        "bias = np.random.randint(0, 50)\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=features, n_informative=informative, bias=bias, noise=noise, random_state=42)\n",
        "\n",
        "print(f'features = {features}, informative = {informative}, noise = {noise}, bias = {bias}')\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPGotLfhF617",
        "outputId": "65b6f9dc-5b0c-4dac-b07d-925dd2bdbe2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features = 5, informative = 1, noise = 0.49260081264699096, bias = 34\n",
            "(100, 5) (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10 - 1, -1, -1):\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "zOG2KN4Qg4Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveMLPRegressor:\n",
        "    def __init__(self, hidden_layer_sizes=(100,), learning_rate=0.001, max_iter=10):\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _weights_initialization(self, input_size, output_size):\n",
        "        # инициализируем hidden_layer_sizes=(100,) разных матриц весов и смещений\n",
        "        for i in range(len(self.hidden_layer_sizes)):\n",
        "            self.weights.append(np.random.normal(0, 0.1, size=input_size))\n",
        "            self.biases.append([np.random.normal(0, 0.1)])\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        input_dim = X_train.shape[1]\n",
        "        output_dim = 1\n",
        "        layers_output = []\n",
        "\n",
        "        self._weights_initialization(input_dim, output_dim)\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            # forward\n",
        "            for i in range(len(self.weights)):\n",
        "                neuron_output = np.dot(X_train, self.weights[i]) + self.biases[i]\n",
        "                after_activation = self._sigmoid(neuron_output)\n",
        "                layers_output.append(after_activation)\n",
        "\n",
        "            # layers_output.shape == (100,) - значения \"y\" после каждого нейрона и активации\n",
        "            error = y_train - layers_output\n",
        "\n",
        "            # backward\n",
        "            for i in range(len(self.weights) - 1, -1, -1):\n",
        "                output_derivative = error *\n",
        "                pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        for i in range(len(self.weights)):\n",
        "            neuron_output = np.dot(X, self.weights[i]) + self.biases[i]\n",
        "            y_pred = self._sigmoid(neuron_output)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "yUUu4dQ1VwQ0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_MLP = NaiveMLPRegressor()\n",
        "naive_MLP.train(X, y)\n",
        "y_pred = naive_MLP.predict(X)"
      ],
      "metadata": {
        "id": "bA418tJWNx7t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'mse = {mean_squared_error(y, y_pred)}, mae = {mean_absolute_error(y, y_pred)}', end='\\n\\n')"
      ],
      "metadata": {
        "id": "6KrIdAcYFW6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для сравнения**"
      ],
      "metadata": {
        "id": "Sg_Zeai-dwSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearnMLP = MLPRegressor(activation='logistic', max_iter=10)\n",
        "sklearnMLP.fit(X, y)\n",
        "y_pred = sklearnMLP.predict(X)"
      ],
      "metadata": {
        "id": "YuvjZcMFKUjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'mse = {mean_squared_error(y, y_pred)}, mae = {mean_absolute_error(y, y_pred)}', end='\\n\\n')"
      ],
      "metadata": {
        "id": "n6FtBw5mKfao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}